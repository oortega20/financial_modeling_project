{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################LOGISTIC REGRESION MODEL FOR STOCKS#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: First create functions that allow for easy access of data\n",
    "#2: Logistic regresion to compute estimate probabilities where i'll probably use l1 regularization to maximize\n",
    "#3: create a function that given data of stocks in a certain period of time predics one time step into the future\n",
    "bin_file = open('sp500_stock_data', 'rb')\n",
    "sp500_stocks, stock_data = pickle.load(bin_file)\n",
    "bin_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_by_sector = sp500_stocks.groupby('Sector').agg(lambda x: list(x))[['Symbol']]\n",
    "stocks_by_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use this sort of formatting \n",
    "#when predicting features based on sector averages\n",
    "sector = stocks_by_sector.loc['Energy'].tolist()[0]\n",
    "sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"set of features we will be using:\n",
    "1: three day daily percent change for close/ variance of.\n",
    "2: seven day daily percent change for close/(high-low)\n",
    "3: perform based on top 3/sectors/and individual stock if trying to predict a trend for one company\n",
    "4: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data['GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####compute the 30 day avg. variance from of closing prices##\n",
    "\n",
    "def variance_calc(num_days, company):\n",
    "    close = stock_data[company]['Adj. Close'].tolist()\n",
    "    moving_variance = []\n",
    "    for i in range(len(close)):\n",
    "        if i < num_days:\n",
    "            moving_variance.append(0)\n",
    "        else:\n",
    "            for_var = np.array(close[i - num_days: i])\n",
    "            moving_variance.append(np.var(for_var))\n",
    "    return moving_variance\n",
    "\n",
    "def expo_moving_avg(num_days, company):\n",
    "    \"\"\"returns list containing num_days exponential moving average of\n",
    "    the company's closing price\"\"\"\n",
    "    close_price = stock_data[company]['Adj. Close'].tolist()\n",
    "    sma, ema = [],[] \n",
    "    multiplier = (2 / (num_days + 1))\n",
    "    for i in range(len(close_price)):\n",
    "        if i < num_days:\n",
    "            sma.append(0)\n",
    "        else:\n",
    "            sma.append(sum(close_price[i - num_days: i]) / num_days)\n",
    "    \n",
    "    for i in range(len(close_price)):\n",
    "        if i < num_days:\n",
    "            ema.append(sma[i])\n",
    "        else:\n",
    "            prev_ema = ema[-1]\n",
    "            ema.append((close_price[i]  - prev_ema) * multiplier + prev_ema)  \n",
    "    return ema\n",
    "\n",
    "#computes the n-day close percent change\n",
    "def close_percent_change(num_days, company):\n",
    "    \"\"\"num_days: an integer (3 or 7)\n",
    "       company: company ticker\n",
    "       adds pandas series containing num_days moving average of stock's closing price\"\"\"\n",
    "    close_price = stock_data[company]['Adj. Close'].tolist()\n",
    "    moving_avg = []\n",
    "    for i in range(len(close_price)):\n",
    "        if i < num_days:\n",
    "            moving_avg.append(0)\n",
    "        else:\n",
    "            start, stop = close_price[i - num_days], close_price[i]\n",
    "            diff = stop - start\n",
    "            percent = diff / start\n",
    "            moving_avg.append(percent)\n",
    "    return moving_avg\n",
    "\n",
    "#computes the nday chaiken money flow\n",
    "def chaiken_money_flow(num_days, company):\n",
    "    close = stock_data[company]['Adj. Close']\n",
    "    high = stock_data[company]['Adj. High']\n",
    "    low = stock_data[company]['Adj. Low']\n",
    "    volume = stock_data[company]['Adj. Volume']\n",
    "    #print(close, high, low, volume)\n",
    "    mfm = ((close - low) - (high - close)) / (high - low)\n",
    "    mfv  = (mfm * volume).tolist()\n",
    "    cmf = []\n",
    "    for i in range(len(close)):\n",
    "        if i < num_days:\n",
    "            cmf.append(0)\n",
    "        else:\n",
    "            s_mfv = sum(mfv[i - num_days: i])\n",
    "            s_v = sum(volume[i - num_days: i])\n",
    "            cmf.append(s_mfv / s_v)\n",
    "    return cmf  \n",
    "#computes the nday relative strength index\n",
    "def rsi(num_days, company):\n",
    "    close = stock_data[company]['Adj. Close'].tolist()\n",
    "    rs, rsi = [],[]\n",
    "    for i in range(len(close)):\n",
    "        if i < num_days:\n",
    "            rs.append(0)\n",
    "        else:\n",
    "            period = close[i - num_days: i]\n",
    "            gain, loss = [],[]\n",
    "            for c in range(1, len(period)):\n",
    "                prev, curr = period[c - 1], period[c]\n",
    "                if prev < curr:\n",
    "                    gain.append(curr - prev)\n",
    "                else:\n",
    "                    loss.append(prev - curr)\n",
    "            if len(loss) != 0 and sum(loss) != 0:\n",
    "                metric = (sum(gain) / num_days) / (sum(loss) / num_days)\n",
    "            else:\n",
    "                metric = (sum(gain) / num_days) / (.001 / num_days)\n",
    "            rs.append(metric)\n",
    "    for i in range(len(rs)):\n",
    "        rsi.append(100 - (100 / (1 + rs[i])))\n",
    "    return rsi\n",
    "\n",
    "#%R = (Highest High – Close) / (Highest High – Lowest Low) X -100\n",
    "\n",
    "def williams_R_indicator(num_days, company):  \n",
    "    high = stock_data[company]['Adj. High'].tolist()\n",
    "    low = stock_data[company]['Adj. Low'].tolist()\n",
    "    close = stock_data[company]['Adj. Close'].tolist()\n",
    "    r_ind = []\n",
    "    for i in range(len(high)):\n",
    "        if i < num_days:\n",
    "            r_ind.append(0)\n",
    "        else:\n",
    "            hh = max(high[i - num_days: i])\n",
    "            ll = min(low[i - num_days: i])\n",
    "            r_val = (hh - close[i]) / (hh - ll) * num_days - 100\n",
    "            r_ind.append(r_val)\n",
    "    return r_ind\n",
    "    \n",
    "    \n",
    "    \n",
    "#CHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(stock_data['AXP'])\n",
    "del(stock_data['SYY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for company in sp500_stocks['Symbol']:\n",
    "    if company in stock_data.keys():\n",
    "        print(company)\n",
    "        stock_data[company]['3 day percent change'] = pd.Series(close_percent_change(3, company), index = stock_data[company].index)\n",
    "        stock_data[company]['7 day percent change'] = pd.Series(close_percent_change(7, company), index = stock_data[company].index)\n",
    "        stock_data[company]['30 day percent change'] = pd.Series(close_percent_change(30, company), index = stock_data[company].index)\n",
    "        stock_data[company]['10 ema'] = pd.Series(expo_moving_avg(10, company), index = stock_data[company].index)\n",
    "        stock_data[company]['3 ema'] = pd.Series(expo_moving_avg(3, company), index = stock_data[company].index)\n",
    "        stock_data[company]['30 day var'] = pd.Series(variance_calc(30, company), index = stock_data[company].index)\n",
    "        stock_data[company]['10 CMF'] = pd.Series(chaiken_money_flow(20, company), index = stock_data[company].index)\n",
    "        stock_data[company]['20 will'] = pd.Series(williams_R_indicator(20, company), index = stock_data[company].index)\n",
    "        stock_data[company]['20 rsi'] = pd.Series(rsi(20, company), index = stock_data[company].index)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Generalized 3,10,30 percent change + top 3 unweighted / weighted########################################\n",
    "#############filter stocks that don't fit the bill`###########################################\n",
    "\n",
    "cutoff = datetime.date(2013, 11, 28)\n",
    "to_del = []\n",
    "for stock in stock_data.keys():\n",
    "    first, last = stock_data[stock].index[0].date(), stock_data[stock].index[-1].date()\n",
    "    print(first, last, cutoff)\n",
    "    if first > cutoff and datetime.date(2018,3,27) != last:\n",
    "        to_del.append(stock)\n",
    "        print(first, last)\n",
    "len(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_for_grouping = {}\n",
    "for stock in stock_data.keys():\n",
    "    stocks_for_grouping[stock] = stock_data[stock]\n",
    "\n",
    "to_del = []\n",
    "for stock in stocks_for_grouping.keys():\n",
    "    stocks_for_grouping[stock] = stocks_for_grouping[stock].iloc[-1000:]\n",
    "    if stocks_for_grouping[stock].shape != (1000, 21):\n",
    "        to_del.append(stock)\n",
    "for stock in to_del:\n",
    "    del(stocks_for_grouping[stock])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_for_grouping['AAPL'].shape, stock_data['AAPL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_matrix = ['3 day percent change', '7 day percent change', '30 day percent change', '10 ema', '3 ema', '30 day var', '10 CMF', '20 will', '20 rsi','Close']\n",
    "for stock in stocks_for_grouping.keys():\n",
    "    stocks_for_grouping[stock] = stocks_for_grouping[stock][feature_matrix]\n",
    "stocks_for_grouping['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stocks_by_sector = sp500_stocks.groupby(sector).agg(lambda x: list(x))[['Symbol']]\n",
    "\n",
    "#gain == 1 loss == 0#\n",
    "def is_loss(company):\n",
    "    close = stocks_for_grouping[company]['Close'].tolist()\n",
    "    is_loss = []\n",
    "    for i in range(len(close)):\n",
    "        if i == 0:\n",
    "            is_loss.append(1)\n",
    "        else:\n",
    "            prev,curr = close[i - 1], close[i]\n",
    "            if prev >= curr:\n",
    "                is_loss.append(0)\n",
    "            else:\n",
    "                is_loss.append(1)\n",
    "    return is_loss\n",
    "\n",
    "for company in stocks_for_grouping.keys():\n",
    "    stocks_for_grouping[company]['gain/loss'] = pd.Series(is_loss(company), index = stocks_for_grouping[company].index)\n",
    "\n",
    "#stocks_for_grouping['MO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_percent_change(sector, num_days):\n",
    "    p_sum, count = np.zeros((1000,)),0\n",
    "    companies = stocks_by_sector.loc[sector].tolist()[0]\n",
    "    for company in companies:\n",
    "        if company in stocks_for_grouping.keys():\n",
    "           # print(stocks_for_grouping[company].keys())\n",
    "            count += 1\n",
    "            if num_days == 3:\n",
    "                p_sum += stocks_for_grouping[company]['3 day percent change']\n",
    "            elif num_days == 7:\n",
    "                p_sum += stocks_for_grouping[company]['7 day percent change']\n",
    "            else:\n",
    "                p_sum += stocks_for_grouping[company]['30 day percent change']\n",
    "    p_sum = (p_sum / count)\n",
    "    p_sum.fillna(0)\n",
    "    return p_sum.tolist()\n",
    "                \n",
    "#    sample_stock = pd.Series(np.zeroes(stocks_data['AAPL']['3 day percent change'], )\n",
    "#stocks_by_sector\n",
    "stocks_for_grouping['AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in stocks_by_sector.index:\n",
    "    companies_by_sector = stocks_by_sector.loc[sector].tolist()[0]\n",
    "    for company in companies_by_sector:\n",
    "        if company in stocks_for_grouping.keys(): \n",
    "            for elem in [3,7,30]:\n",
    "                print(company)\n",
    "                stocks_for_grouping[company][str(elem) + ' sector_avg'] = pd.Series(sector_percent_change(sector, elem),index = stocks_for_grouping[company].index)\n",
    "                stocks_for_grouping[company][str(elem) + ' sector_avg'] = stocks_for_grouping[company][str(elem) + ' sector_avg'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########tables of weighted versus unweighted top performers##########\n",
    "\n",
    "weighted = (sp500_stocks['Symbol'] == 'AAPL') | (sp500_stocks['Symbol'] == 'AMZN') | (sp500_stocks['Symbol'] == 'MSFT')\n",
    "non_weighted = (sp500_stocks['Symbol'] == 'NFLX') | (sp500_stocks['Symbol'] == 'XL') | (sp500_stocks['Symbol'] == 'TRIP')\n",
    "top_3_weighted = sp500_stocks.loc[weighted]['Symbol']\n",
    "top_3_nweighted = sp500_stocks.loc[non_weighted]['Symbol']\n",
    "top_3_nweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_percent_change(stocks, num_days):\n",
    "    sum_stocks = np.zeros((1000))\n",
    "    for company in stocks:\n",
    "        if num_days == 30:\n",
    "            sum_stocks += stocks_for_grouping[company]['30 day percent change']\n",
    "        elif num_days == 7:\n",
    "            sum_stocks += stocks_for_grouping[company]['7 day percent change']\n",
    "        else:\n",
    "            sum_stocks += stocks_for_grouping[company]['3 day percent change']\n",
    "    sum_stocks = (sum_stocks / 3).fillna(0)\n",
    "    return sum_stocks.tolist()\n",
    "\n",
    "for company in stocks_for_grouping.keys():\n",
    "    print(company)\n",
    "    for elem in [3,7,30]:\n",
    "        stocks_for_grouping[company]['nw_top3'] = pd.Series(top_3_percent_change(top_3_nweighted, elem), index = stocks_for_grouping[company].index)\n",
    "        stocks_for_grouping[company]['w_top3'] = pd.Series(top_3_percent_change(top_3_weighted, elem), index = stocks_for_grouping[company].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_for_grouping['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(company_ticker):\n",
    "    ###currently predicts gain loss patters for the next consequtive 100 days##\n",
    "    ##returns:(prediction score, predictions, actual values)\n",
    "    X = stocks_for_grouping[company_ticker].drop(['gain/loss'], axis=1).values\n",
    "    y = stocks_for_grouping[company_ticker]['gain/loss'].values\n",
    "    X_train, X_test, y_train, y_test = X[:900], X[900:], y[:900],y[900:]\n",
    "    clf = LogisticRegression(max_iter=10000, penalty='l2', solver = 'liblinear')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    tup = clf.score(X_test, y_test), clf.predict(X_test), y_test\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('GOOGL')[0], train_model('AMZN')[0], train_model('FB')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##graph predictions of wins/loss versus actual google win loss patterns for the prev 100 days\n",
    "goog_inf = train_model('GOOG')\n",
    "fb_inf = train_model('FB')\n",
    "amzn_inf = train_model('AMZN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.xlabel('Days Ahead')\n",
    "plt.ylabel('Gain\\Loss on given day')\n",
    "plt.title('Google gain\\loss Predictions versus Values')\n",
    "\n",
    "x = list(range(100))\n",
    "act = goog_inf[2]\n",
    "pred = goog_inf[1]\n",
    "df = pd.DataFrame(np.c_[pred, act], index=x, columns = ['GOOGLE GAIN\\LOSS PREDICTIONS', 'GOOGLE GAIN\\LOSS'])\n",
    "\n",
    "ax = sns.lineplot(data=df)\n",
    "plt.savefig('google.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.xlabel('Days Ahead')\n",
    "plt.ylabel('Gain\\Loss on given day')\n",
    "plt.title('FB gain\\loss Predictions versus Values')\n",
    "\n",
    "x = list(range(100))\n",
    "act = fb_inf[2]\n",
    "pred = fb_inf[1]\n",
    "df = pd.DataFrame(np.c_[pred, act], index=x, columns = ['FB GAIN\\LOSS PREDICTIONS', 'FB GAIN\\LOSS'])\n",
    "\n",
    "ax = sns.lineplot(data=df)\n",
    "plt.savefig('fb.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.xlabel('Days Ahead')\n",
    "plt.ylabel('Gain\\Loss on given day')\n",
    "plt.title('Amazon gain\\loss Predictions versus Values')\n",
    "\n",
    "x = list(range(100))\n",
    "act = amzn_inf[2]\n",
    "pred = amzn_inf[1]\n",
    "df = pd.DataFrame(np.c_[pred, act], index=x, columns = ['AMZN GAIN\\LOSS PREDICTIONS', 'AMZN GAIN\\LOSS'])\n",
    "\n",
    "ax = sns.lineplot(data=df)\n",
    "plt.savefig('amzn.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
